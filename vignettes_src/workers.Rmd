---
title: "R and the DIDE cluster, workers"
author: "Rich FitzJohn"
date: "`r Sys.Date()`"
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Workers}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

``` {r echo = FALSE,results = "hide"}
source("common.R")
```

# Running heaps of jobs without annoying your colleagues

If you have thousands and thousands of jobs to submit at once you
may not want to flood the cluster with them all at once.  Each job
submission is relatively slow (the HPC tools that the web interface
has to use are relatively slow).  The actual queue that the cluster
uses doesn't seem to like processing tens of thousands of job, and
can slow down.  And if you take up the whole cluster someone may
come and knock on your office and complain at you.  At the same
time, batching your jobs up into little bits and manually sending
them off is a pain and work better done by a computer.

An alternative is to submit a set of "workers" to the cluster, and
then submit jobs to them.  This is done with the
[`rrq`](https://github.com/mrc-ide/rrq) package, along with a
[`redis`](http://redis.io) server running on the cluster.

To get started you will need to install the rrq package locally.
This will also install [`redux`](https://github.com/richfitz/redux)
which can be a bit of a pain to install on some platforms (talk to
Rich if you have trouble, but it's on CRAN now so that should help).

```r
drat::add("mrc-ide")
install.packages("rrq")
```

or

```r
source("https://mrc-ide.github.io/didehpc/install#extras")
```

``` {r }
context::context_log_start()
root <- "context_workers"
```

There is currently an issue here where the workers try and process
jobs *too* efficiently, before the task has been written to disk.
To work around this, there is a _very_ experimental support for
storing tasks in a SQL database.  If you're going to try this,
please let Rich know because there are gotchas, and we need to
think about how to clear out your data (plus some major issues
around data security and privacy).
``` {r }
ctx <- context::context_save(root,
                             packages = "ape",
                             sources = "mysources.R",
                             storage_type = didehpc:::storage_driver_psql())
```

There are two ways we can proceed from here; the first - "workers"
- is very similar to the non-worker workflow and is described
first.  The second - "rrq" - is a bit more involved and is
described second.

## Workers

Then configure and create the queue:
``` {r }
config <- didehpc::didehpc_config(use_workers = TRUE)

obj <- didehpc::queue_didehpc(ctx, config = config)
```

All passing `use_workers` here will do is arrange to install `rrq`,
`redux` and their dependencies on the cluster, plus enable a couple
of methods in the queue objects.  Aside from that it's essentially
the same queue as before.

The big difference is that submitting jobs (either with `enqueue`
or via one of the `queuer` bulk submission functions) will no
longer submit jobs to the DIDE queue, but to an internal Redis
queue.

You must submit actual workers (you can do this before or after
submitting jobs but I'll do it first here).  The argument is the
number of workers to submit.
``` {r }
workers <- obj$submit_workers(5)
workers
```

``` {r echo = FALSE}
Sys.sleep(0.5)
```

All workers get names in the form `<adjective>_<animal>_<integer>`
so that you can remember which workers you set off.  They will turn
off after 10 minutes of inactivity by default (you can tweak this
with the `worker_timeout` argument to `didehpc_config` or by
sending a `TIMEOUT_SET` message).

Submitting jobs works as before, but should hopefully be a little
faster:
``` {r }
t <- obj$enqueue(make_tree(5))
t$wait(5)
```

One advantage over the usual queuing approach here is that you will
not wait for anyone elses jobs to complete once you have reserved
your workers.

You can see what your workers have been up to with the
`workers_log_tail` command:
``` {r }
objrrq$worker_log_tail(n = Inf)
```

The `time` column may be tweaked into something a bit more
practical soon.

As before, logging works on a per-task basis:
``` {r }
t$log()
```

Find out how long your workers will persist for:
``` {r }
id <- obj$rrq$send_message("TIMEOUT_GET")
obj$rrq$get_responses(id, timeout = 10)
```

Other than that, hopefully everything else continues as normal.  We
can submit a bunch of jobs and run them using `queuer::qlapply`:
``` {r }
sizes <- 3:8
grp <- queuer::qlapply(sizes, make_tree, obj)
```

Task status:
``` {r }
grp$status()
```

Collect the results:
``` {r }
res <- grp$wait(5)
res
```

While workers will turn off automatically, it's polite to turn them
off as soon as you're done using `obj$stop_workers()`

Alternatively, after submitting a bunch of jobs you can run
```r
obj$rrq$send_message("TIMEOUT_SET", 0)
```

which will mean that the workers will stop immediately after not
recieving a task (so after they finish processing all your jobs
they'll stop one by one).  Practically this still takes one minute
because that's the polling timeout time (I may be able to improve
this later).
``` {r }
obj$stop_workers()
Sys.sleep(1)
objrrq$worker_log_tail(workers, n = Inf)
obj$rrq$destroy()
obj$db$destroy()
```

## rrq

In this model, we create a very lightweight queue which in turn
creates very lightweight tasks.  This avoids even more overhead
than the approach above, though it can be more difficult to debug
because less information is saved.  Rather than round-tripping data
through the disk, everything goes via the redis server.

The other difference here is that jobs can be run on the cluster
using the same approach, so you can submit a task that controlls
some (potentially very large) number of workers, submitting and
collecting tasks from them.

The first part here looks very similar
``` {r }
root <- "context_rrq"
ctx <- context::context_save(root,
                             packages = "ape",
                             sources = "mysources.R")

config <- didehpc::didehpc_config(use_rrq = TRUE)
obj <- didehpc::queue_didehpc(ctx, config = config)
```

We still submit workers
``` {r }
workers <- obj$submit_workers(100)
workers
```

echo = FALSE
``` {r }
Sys.sleep(0.5)
```

To send tasks to these workers we need a *second* type of queue:
``` {r }
rrq <- obj$rrq_controller()
rrq
```

This will look and act a lot like the main didehpc queue
controller, but with a few differences.  Tasks will come back as
plain strings rather than user-friendly objects and `lapply` and
`enqueue_bulk` are now blocking operations.  The payback for this
is potentially very fast task turnarounds and better behaviour with
the disk under heavy load.
``` {r }
t <- rrq$enqueue(sin(1))
rrq$task_wait(t, 10)
```

For example; submitting 50 trivial tasks to our pool of five
workers and retrieving the results:
``` {r }
system.time(res <- rrq$lapply(1:50, sin))
```

or 500 tasks:
``` {r }
system.time(res <- rrq$lapply(1:500, sin))
```

Across the network, the latency here is ~1/1000 s per task.  On
fi--didemrchnb it will hopefully be a bit faster because of the
infiniband network.

``` {r }
rrq$workers_stop()
rrq$destroy()
```

To use this, we'll submit workers as above, then submit a job that
will use the workers.

``` {r echo = FALSE, results = "asis"}
writeLines(c("```r", readLines("mysources-rrq.R"), "```"))
```

In this code, there is a function `simulation` that takes `nsteps`
steps and in each steps samples `nsamples` random numbers.  The
function used to do this is called `slow_rnorm` -- imagine that
this is some hard to sample from distribution.  The pattern here is
that the simulation has both a serial and a parallel component;
each iteration a bunch of things happen that can be done at once
(the samples) but between steps a naturally serial operation
happens (sorting the numbers).  This is a contrived example but
this pattern is fairly common in practice.
``` {r }
ctx <- context::context_save(root,
                             sources = "mysources-rrq.R")
config <- didehpc::didehpc_config(use_rrq = TRUE)
obj <- didehpc::queue_didehpc(ctx, config = config)
obj$submit_workers(5)
```

``` {r echo = FALSE}
Sys.sleep(0.5)
```

Now, we can submit a task that will use this set of workers
``` {r }
t <- obj$enqueue(simulation(15, 5))
res <- t$wait(120)
res
```

Let's scale it up; suppose we want 100 samples per step:
``` {r }
t2 <- obj$enqueue(simulation(15, 100))
```

This is going to take 20x longer!  But there's space on the cluster:
``` {r }
obj$cluster_load(nodes = FALSE)
```

So let's submit a bunch more workers; they will immediately start
working on the tasks as soon as they are submitted.  In fact;
because submitting workers is relatively slow compared with running
tasks, they may not all get onto the cluster before the work is
complete.
``` {r }
obj$submit_workers(20)

objrrq$worker_len()
objrrq$worker_list()
objrrq$worker_status()

res <- t2$wait(120)
res
```

Turn off all our workers
``` {r }
objrrq$worker_stop()
```

And delete all the data that we created.  This step gets some
tweaking soon.
``` {r }
obj$rrq$destroy()
```
