---
title: "Workers"
author: "Rich FitzJohn"
date: "2021-04-08"
output:
  rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Workers}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

<!-- DO NOT EDIT THIS FILE - see vignettes_src and make changes there -->

# Running heaps of jobs without annoying your colleagues

If you have thousands and thousands of jobs to submit at once you
may not want to flood the cluster with them all at once.  Each job
submission is relatively slow (the HPC tools that the web interface
has to use are relatively slow).  The actual queue that the cluster
uses doesn't seem to like processing tens of thousands of job, and
can slow down.  And if you take up the whole cluster someone may
come and knock on your office and complain at you.  At the same
time, batching your jobs up into little bits and manually sending
them off is a pain and work better done by a computer.

An alternative is to submit a set of "workers" to the cluster, and
then submit jobs to them.  This is done with the
[`rrq`](https://github.com/mrc-ide/rrq) package, along with a
[`redis`](https://redis.io) server running on the cluster.

## Overview

## Getting started

To get started you will need to install the `rrq` package locally.

```r
drat::add("mrc-ide")
install.packages("rrq")
```

Then construct the context as before


```r
root <- "context"
ctx <- context::context_save(root, sources = "mysources.R")
```

```
## [ init:id   ]  423be27b1aff9ac9200b46ff2510219c
```

```
## [ init:db   ]  rds
```

```
## [ init:path ]  context
```

```
## [ save:id   ]  88f88ed6d573805f0d83f24164609ccc
```

```
## [ save:name ]  groundable_goldfish
```

There are two ways we can proceed from here; the first - "workers"
- is very similar to the non-worker workflow and is described
first.  The second - "rrq" - is a bit more involved and is
described second.

## Workers

Then configure and create the queue; the `use_workers` argument is important here as it:

* ensures that the `rrq` package is available on the cluster, where your workers will run
* changes the behaviour of the `$enqueue` method so that jobs are not sent to the HPC scheduler but to the `rrq` scheduler
* enables the `$submit_workers` method which you will use to create workers on the cluster

However, everything else will appear the same.


```r
config <- didehpc::didehpc_config(use_workers = TRUE)
obj <- didehpc::queue_didehpc(ctx, config = config)
```

```
## Loading context 88f88ed6d573805f0d83f24164609ccc
```

```
## [ context   ]  88f88ed6d573805f0d83f24164609ccc
```

```
## [ library   ]
```

```
## [ namespace ]
```

```
## [ source    ]  mysources.R
```

```
## Running installation script on cluster
```

```
## [-]  0s ...[\]  0s RUNNING                                                                              CONAN THE LIBRARIAN I: the bootstrappening
## Installing bootstrap library into 'T:\conan\bootstrap\4.0'
## Success!
## CONAN THE LIBRARIAN
## Library:   Q:\cluster_testing\20210408-173139\context\lib\windows\4.0
## Bootstrap: T:\conan\bootstrap\4.0
## Cache:     Q:\cluster_testing\20210408-173139\context\conan\cache/pkg
## Policy:    lazy
## Repos:
##  * https://mrc-ide.github.io/didehpc-pkgs
##  * https://cloud.r-project.org
## Packages:
##  * context
##  * rrq
##  * callr
## [|]  1s RUNNING[/]  2s RUNNING                                                                              i Loading metadata database
## [-]  3s RUNNING[\]  4s RUNNING                                                                              v Loading metadata database ... done
##
## [|]  5s RUNNING                                                                              i Getting 23 pkgs (10.80 MB) and 2 pkgs with unknown sizes
## [/]  6s RUNNING[-]  7s RUNNING[\]  8s RUNNING[|]  9s RUNNING                                                                              v Got context 0.3.0 (source) (45.34 kB)
## v Got R6 2.5.0 (windows) (84.11 kB)
## v Got askpass 1.1 (windows) (243.58 kB)
## v Got crayon 1.4.1 (windows) (141.83 kB)
## v Got rrq 0.2.18 (source) (63.15 kB)
## v Got digest 0.6.27 (windows) (268.66 kB)
## v Got ids 1.0.1 (windows) (123.93 kB)
## v Got sys 3.4 (windows) (59.90 kB)
## v Got uuid 0.1-4 (windows) (33.77 kB)
## [/] 10s RUNNING                                                                              v Got pkgconfig 2.0.3 (windows) (22.34 kB)
## v Got lifecycle 1.0.0 (windows) (111.19 kB)
## v Got docopt 0.7.1 (windows) (245.71 kB)
## v Got glue 1.4.2 (windows) (155.51 kB)
## v Got hms 1.0.0 (windows) (103.58 kB)
## v Got prettyunits 1.1.1 (windows) (37.71 kB)
## [-] 11s RUNNING                                                                              v Got progress 1.2.2 (windows) (85.86 kB)
## v Got redux 1.1.0 (windows) (287.94 kB)
## v Got vctrs 0.3.7 (windows) (1.25 MB)
## v Got callr 3.6.0 (windows) (432.79 kB)
## v Got openssl 1.4.3 (windows) (3.99 MB)
## v Got rlang 0.4.10 (windows) (1.20 MB)
## v Got ellipsis 0.3.1 (windows) (46.12 kB)
## v Got processx 3.5.1 (windows) (1.24 MB)
## v Got storr 1.2.5 (windows) (401.14 kB)
## v Got ps 1.6.0 (windows) (775.96 kB)
## [\] 12s RUNNING[|] 13s RUNNING                                                                              v Installed R6 2.5.0  (1.4s)
## v Installed crayon 1.4.1  (1.4s)
## v Installed ids 1.0.1  (1.5s)
## v Installed askpass 1.1  (1.7s)
## v Installed sys 3.4  (1.8s)
## v Installed uuid 0.1-4  (1.9s)
## [/] 14s RUNNING                                                                              v Installed docopt 0.7.1  (2s)
## v Installed storr 1.2.5  (2.5s)
## v Installed ellipsis 0.3.1  (2.4s)
## v Installed glue 1.4.2  (2.6s)
## [-] 15s RUNNING                                                                              v Installed digest 0.6.27  (3.3s)
## v Installed openssl 1.4.3  (3.5s)
## i Building context 0.3.0
## [\] 19s RUNNING[|] 20s RUNNING                                                                              v Installed hms 1.0.0  (7s)
## [/] 21s RUNNING                                                                              v Installed lifecycle 1.0.0  (7.1s)
## v Installed pkgconfig 2.0.3  (7.4s)
## v Installed prettyunits 1.1.1  (7.6s)
## [-] 22s RUNNING                                                                              v Installed progress 1.2.2  (7.6s)
## v Installed redux 1.1.0  (7.7s)
## v Installed rlang 0.4.10  (7.6s)
## v Installed vctrs 0.3.7  (7.8s)
## [\] 23s RUNNING                                                                              v Installed callr 3.6.0  (7.8s)
## v Installed processx 3.5.1  (7.7s)
## [|] 24s RUNNING                                                                              v Installed ps 1.6.0  (8.3s)
## i Building rrq 0.2.18
## [/] 25s RUNNING                                                                              v Built context 0.3.0 (5s)
## [-] 26s RUNNING                                                                              v Installed context 0.3.0  (657ms)
## [\] 27s RUNNING[|] 28s RUNNING[/] 29s RUNNING[-] 30s RUNNING[\] 31s RUNNING                                                                              v Built rrq 0.2.18 (7.1s)
## [|] 32s RUNNING                                                                              v Installed rrq 0.2.18  (282ms)
## v Summary:   25 new  in 2m 2.5s
##                                                                               Done!
```

You can now submit


```r
t <- obj$enqueue(random_walk(0, 10))
```

This job will stay pending forever as the HPC scheduler will never run it


```r
t$status()
```

```
## [1] "PENDING"
```

```r
t$times()
```

```
##                            task_id           submitted started finished
## 1 6203e8be1f233385b30f99f1c27548b1 2021-04-08 17:34:56    <NA>     <NA>
##    waiting running idle
## 1 0.263576      NA   NA
```

You must submit actual workers in order to actually run things. This could have been done before submitting the tasks, though workers will time out after 10 minutes of inactivity, if you have very many jobs to save your workers might exit before the work starts!

The argument is the number of workers to submit. Each worker is equivalent to a job that your configuration would otherwise create (in terms of cores selected).


```r
workers <- obj$submit_workers(2)
```

```
## Submitting 2 workers with base name 'pompous_vulpesvulpes'
```

```
## submitting (-) [===================================] 100% | giving up in 600 s
```

```r
workers
```

```
## [1] "pompous_vulpesvulpes_1" "pompous_vulpesvulpes_2"
```

All workers get names in the form `<adjective>_<animal>_<integer>`
so that you can remember which workers you set off.  They will turn
off after 10 minutes of inactivity by default (you can tweak this
with the `worker_timeout` argument to `didehpc_config` or by
sending a `TIMEOUT_SET` message).

One advantage over the usual queuing approach here is that you will
not wait for anyone elses jobs to complete once you have reserved
your workers.


```r
t$wait(10)
```

```
## (-) waiting for 6203e8b...8b1, giving up in 9.5 s (\) waiting for 6203e8b...8b1,
## giving up in 9.0 s
```

```
##  [1] 1.1387376 1.9015383 1.4091530 1.1044008 0.1655079 1.0692514 1.2235822
##  [8] 1.8781213 1.0132392 0.7237403
```

We're going to interact with the rrq object a bit


```r
rrq <- obj$rrq_controller()
rrq
```

```
## <rrq_controller>
##   Public:
##     bulk_wait: function (x, timeout = Inf, time_poll = NULL, progress = NULL)
##     con: redis_api, R6
##     db: storr, R6
##     deferred_list: function ()
##     destroy: function (delete = TRUE, worker_stop_type = "message", worker_stop_timeout = 0)
##     enqueue: function (expr, envir = parent.frame(), key_complete = NULL,
##     enqueue_: function (expr, envir = parent.frame(), key_complete = NULL,
##     enqueue_bulk: function (x, fun, ..., dots = NULL, envir = parent.frame(), queue = NULL,
##     enqueue_bulk_: function (x, fun, ..., dots = NULL, envir = parent.frame(), queue = NULL,
##     envir: function (create, notify = TRUE)
##     initialize: function (queue_id, con)
##     keys: list
##     lapply: function (x, fun, ..., dots = NULL, envir = parent.frame(), queue = NULL,
##     lapply_: function (x, fun, ..., dots = NULL, envir = parent.frame(), queue = NULL,
##     message_get_response: function (message_id, worker_ids = NULL, named = TRUE, delete = FALSE,
##     message_has_response: function (message_id, worker_ids = NULL, named = TRUE)
##     message_response_ids: function (worker_id)
##     message_send: function (command, args = NULL, worker_ids = NULL)
##     message_send_and_wait: function (command, args = NULL, worker_ids = NULL, named = TRUE,
##     queue_id: 88f88ed6d573805f0d83f24164609ccc
##     queue_length: function (queue = NULL)
##     queue_list: function (queue = NULL)
##     queue_remove: function (task_ids, queue = NULL)
##     task_cancel: function (task_id)
##     task_data: function (task_id)
##     task_delete: function (task_ids, check = TRUE)
##     task_exists: function (task_ids = NULL)
##     task_list: function ()
##     task_overview: function (task_ids = NULL)
##     task_position: function (task_ids, missing = 0L, queue = NULL)
##     task_preceeding: function (task_id, queue = NULL)
##     task_progress: function (task_id)
##     task_result: function (task_id)
##     task_status: function (task_ids = NULL)
##     task_wait: function (task_id, timeout = Inf, time_poll = NULL, progress = NULL,
##     tasks_result: function (task_ids)
##     tasks_wait: function (task_ids, timeout = Inf, time_poll = NULL, progress = NULL,
##     worker_config_list: function ()
##     worker_config_read: function (name)
##     worker_config_save: function (name, time_poll = NULL, timeout = NULL, queue = NULL,
##     worker_delete_exited: function (worker_ids = NULL)
##     worker_detect_exited: function ()
##     worker_info: function (worker_ids = NULL)
##     worker_len: function ()
##     worker_list: function ()
##     worker_list_exited: function ()
##     worker_load: function (worker_ids = NULL)
##     worker_log_tail: function (worker_ids = NULL, n = 1)
##     worker_process_log: function (worker_id)
##     worker_status: function (worker_ids = NULL)
##     worker_stop: function (worker_ids = NULL, type = "message", timeout = 0, time_poll = 1,
##     worker_task_id: function (worker_ids = NULL)
```

This is another R6 object, though this one at least has decent documentation - see the `rrq::rrq_controller` for details of each method

You can see what your workers have been up to with the
`workers_log_tail` command:


```r
rrq$worker_log_tail(n = Inf)
```

```
##                worker_id       time       command
## 1 pompous_vulpesvulpes_1 1617899698         ALIVE
## 2 pompous_vulpesvulpes_1 1617899698    TASK_START
## 3 pompous_vulpesvulpes_2 1617899699         ALIVE
## 4 pompous_vulpesvulpes_1 1617899699 TASK_COMPLETE
##                            message
## 1
## 2 d56a50551efb9ddd54753781761437d4
## 3
## 4 d56a50551efb9ddd54753781761437d4
```

The `time` column represents seconds - relative seconds should still be useful here.

As before, logging works on a per-task basis:

```r
t$log()
```

```
## [ open:db   ]  rds
## [ context   ]  88f88ed6d573805f0d83f24164609ccc
## [ library   ]
## [ namespace ]
## [ source    ]  mysources.R
## [ root      ]  context
## [ context   ]  88f88ed6d573805f0d83f24164609ccc
## [ task      ]  6203e8be1f233385b30f99f1c27548b1
## [ expr      ]  random_walk(0, 10)
## [ start     ]  2021-04-08 17:34:59.126
## [ ok        ]
## [ end       ]  2021-04-08 17:34:59.282
```

Find out how long your workers will persist for:


```r
rrq$message_send_and_wait("TIMEOUT_GET", worker_ids = workers)
```

```
## $pompous_vulpesvulpes_1
##   timeout remaining
##       600       600
##
## $pompous_vulpesvulpes_2
##   timeout remaining
##   600.000   598.875
```

Other than that, hopefully everything else continues as normal.  We
can submit a bunch of jobs and run them using `$lapply`:


```r
sizes <- 3:8
grp <- obj$lapply(sizes, random_walk, x = 0)
```

```
## Creating bundle: 'botanic_cob'
```

```
## [ bulk      ]  Creating 6 tasks
```

```
## submitting 6 tasks
```

Task status:

```r
grp$status()
```

```
## b19179d1f60ebe93c9f5bd5509a0482f fecc9838bb082293fdf9d35886216dc6
##                        "RUNNING"                        "PENDING"
## a937220398738b507a9974e37d1a6d39 5c55905b0bcd247db5690e20e1e340f1
##                        "PENDING"                        "PENDING"
## e005d389423fdfdacbd78b498eebdac6 d29fde3a160f89bb9bf6960fc83ad81f
##                        "PENDING"                        "PENDING"
```

Collect the results:

```r
res <- grp$wait(5)
```

```
## (-) [===============================>----------------] 67% | giving up in 4 s
## (\) [===============================>----------------] 67% | giving up in 4 s
## (|) [================================================] 100% | giving up in 3 s
```

```r
res
```

```
## [[1]]
## [1]  0.4740505 -0.0885686  0.4877967
##
## [[2]]
## [1] 0.836734 2.066275 3.236791 3.486007
##
## [[3]]
## [1] 1.366285 1.384638 1.884508 2.284558 1.965855
##
## [[4]]
## [1] -1.51424319 -0.23091026 -0.07363942 -1.46119456 -2.44535905 -2.51154256
##
## [[5]]
## [1]  0.41197442 -1.26692996 -0.70134926  0.09532039 -1.26262647 -0.95169576
## [7] -1.14892325
##
## [[6]]
## [1]  0.50682975  0.50097494 -0.27726381 -2.85940363 -3.81332453 -2.68499675
## [7] -2.55390563 -0.05998136
```

While workers will turn off automatically, it's polite to turn them
off as soon as you're done using `obj$stop_workers()`

Alternatively, after submitting a bunch of jobs you can run

```r
rrq$message_send("TIMEOUT_SET", 0)
```

which will mean that the workers will stop immediately after not
recieving a task (so after they finish processing all your jobs
they'll stop one by one).  Practically this still takes one minute
because that's the polling timeout time (I may be able to improve
this later).


```r
obj$stop_workers()
Sys.sleep(1)
rrq$worker_log_tail(workers, n = Inf)
```

```
##                 worker_id       time       command
## 1  pompous_vulpesvulpes_1 1617899698         ALIVE
## 2  pompous_vulpesvulpes_1 1617899698    TASK_START
## 3  pompous_vulpesvulpes_2 1617899699         ALIVE
## 4  pompous_vulpesvulpes_1 1617899699 TASK_COMPLETE
## 5  pompous_vulpesvulpes_1 1617899700       MESSAGE
## 6  pompous_vulpesvulpes_1 1617899700      RESPONSE
## 7  pompous_vulpesvulpes_2 1617899700       MESSAGE
## 8  pompous_vulpesvulpes_2 1617899700      RESPONSE
## 9  pompous_vulpesvulpes_1 1617899701    TASK_START
## 10 pompous_vulpesvulpes_2 1617899701    TASK_START
## 11 pompous_vulpesvulpes_1 1617899702 TASK_COMPLETE
## 12 pompous_vulpesvulpes_1 1617899702    TASK_START
## 13 pompous_vulpesvulpes_2 1617899702 TASK_COMPLETE
## 14 pompous_vulpesvulpes_2 1617899702    TASK_START
## 15 pompous_vulpesvulpes_1 1617899702 TASK_COMPLETE
## 16 pompous_vulpesvulpes_1 1617899702    TASK_START
## 17 pompous_vulpesvulpes_2 1617899703 TASK_COMPLETE
## 18 pompous_vulpesvulpes_2 1617899703    TASK_START
## 19 pompous_vulpesvulpes_1 1617899703 TASK_COMPLETE
## 20 pompous_vulpesvulpes_2 1617899703 TASK_COMPLETE
## 21 pompous_vulpesvulpes_1 1617899704       MESSAGE
## 22 pompous_vulpesvulpes_1 1617899704      RESPONSE
## 23 pompous_vulpesvulpes_1 1617899704          STOP
## 24 pompous_vulpesvulpes_2 1617899704       MESSAGE
## 25 pompous_vulpesvulpes_2 1617899704      RESPONSE
## 26 pompous_vulpesvulpes_2 1617899704          STOP
##                             message
## 1
## 2  d56a50551efb9ddd54753781761437d4
## 3
## 4  d56a50551efb9ddd54753781761437d4
## 5                       TIMEOUT_GET
## 6                       TIMEOUT_GET
## 7                       TIMEOUT_GET
## 8                       TIMEOUT_GET
## 9  02ff04b1c68645314acfcecba59332c4
## 10 16ff5912fee6220bf67e784b3174f05a
## 11 02ff04b1c68645314acfcecba59332c4
## 12 d00dea56ad655845fce9a3b950ffcfc3
## 13 16ff5912fee6220bf67e784b3174f05a
## 14 52eabc1766b7c7e269bdc4037e4677cd
## 15 d00dea56ad655845fce9a3b950ffcfc3
## 16 935c66c69ece8f1940f399c56dcff9b0
## 17 52eabc1766b7c7e269bdc4037e4677cd
## 18 ba09de85b769d0bcbaf81d5c59ff132b
## 19 935c66c69ece8f1940f399c56dcff9b0
## 20 ba09de85b769d0bcbaf81d5c59ff132b
## 21                             STOP
## 22                             STOP
## 23                         OK (BYE)
## 24                             STOP
## 25                             STOP
## 26                         OK (BYE)
```

```r
rrq$destroy()
```

## rrq

In this model, we create a very lightweight queue which in turn
creates very lightweight tasks.  This avoids even more overhead
than the approach above, though it can be more difficult to debug
because less information is saved.  Rather than round-tripping data
through the disk, everything goes via the redis server.

The first part here looks very similar, except that we use `use_rrq = TRUE` rather than `use_workers`


```r
config <- didehpc::didehpc_config(use_rrq = TRUE)
obj <- didehpc::queue_didehpc(ctx, config = config)
```

```
## Loading context 88f88ed6d573805f0d83f24164609ccc
```

```
## [ context   ]  88f88ed6d573805f0d83f24164609ccc
```

```
## [ library   ]
```

```
## [ namespace ]
```

```
## [ source    ]  mysources.R
```

We still submit workers


```r
workers <- obj$submit_workers(10)
```

```
## Submitting 10 workers with base name 'socialistic_rabidsquirrel'
```

```
## submitting (-) [======>----------------------------] 20% | giving up in 599 s
## submitting (\) [=========>-------------------------] 30% | giving up in 599 s
## submitting (|) [=============>---------------------] 40% | giving up in 598 s
## submitting (/) [=================>-----------------] 50% | giving up in 598 s
## submitting (-) [====================>--------------] 60% | giving up in 597 s
## submitting (\) [=======================>-----------] 70% | giving up in 597 s
## submitting (|) [===========================>-------] 80% | giving up in 597 s
## submitting (/) [===============================>---] 90% | giving up in 596 s
## submitting (-) [===================================] 100% | giving up in 595 s
```

```r
workers
```

```
##  [1] "socialistic_rabidsquirrel_1"  "socialistic_rabidsquirrel_2"
##  [3] "socialistic_rabidsquirrel_3"  "socialistic_rabidsquirrel_4"
##  [5] "socialistic_rabidsquirrel_5"  "socialistic_rabidsquirrel_6"
##  [7] "socialistic_rabidsquirrel_7"  "socialistic_rabidsquirrel_8"
##  [9] "socialistic_rabidsquirrel_9"  "socialistic_rabidsquirrel_10"
```

To send tasks to these workers we directly use the `rrq_controller` object - we'll not use the `queue_didehpc` object from this point.


```r
rrq <- obj$rrq_controller()
```

This will look and act a lot like the main didehpc queue controller, but with a few differences.  Tasks will come back as plain strings rather than user-friendly objects and `lapply` and `enqueue_bulk` are now blocking operations by default. Most tasks will clean up after they delete rather than leaving a persistant record on disk.  The payback for this is potentially very fast task turnarounds and better behaviour with the disk under heavy load.


```r
t <- rrq$enqueue(sin(1))
rrq$task_wait(t, 10)
```

```
## [1] 0.841471
```

For example; submitting 50 trivial tasks to our pool of workers and retrieving the results:


```r
system.time(res <- rrq$lapply(1:50, sin))
```

```
##    user  system elapsed
##   0.004   0.007   0.049
```

or 500 tasks:


```r
system.time(res <- rrq$lapply(1:500, sin))
```

```
##    user  system elapsed
##   0.061   0.016   0.466
```

Across the network, the latency here is ~1/600 s per task.  On fi--didemrchnb it will hopefully be a bit faster because of the infiniband network.


```r
rrq$worker_stop()
rrq$destroy()
```

It is theoretically possible to submit a cluster job that creates an `rrq_controller` and controls the second queue. To do that you need to write function like:

```
get_rrq_controller <- function(x, ...) {
  queue_id <- Sys.getenv("CONTEXT_ID", "")
  stopifnot(queue_id != "")
  rrq::rrq_controller(queue_id)
}
```

within your sources, then you can use it in place of running (say) a `lapply()` call in your code. This approach allows a relatively simple form of inter-process communication. Talk to Rich if this is something you might have a use for, if you have simulation needs that are larger than a single node.

## Cleaning up

Above we use `rrq$destroy()` to clean up every trace of the queue. Peridically we may flush the entire Redis database, or set all keys to expire after a day or so. Do not leave any important information in here please.
